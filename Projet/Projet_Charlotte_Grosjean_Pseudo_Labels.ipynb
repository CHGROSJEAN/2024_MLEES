{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPg+RB75u8k/49PCeDshp/u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CHGROSJEAN/2024_MLEES/blob/main/Projet/Projet_Charlotte_Grosjean_Pseudo_Labels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Import libraries and data\n"
      ],
      "metadata": {
        "id": "QXksE2TVITc1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Frist step, simple GMM for 2 stations : Grand-Vennes and Riand-Pr√©."
      ],
      "metadata": {
        "id": "x5d3GYZoXr6h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "pigbLfeItiB-"
      },
      "outputs": [],
      "source": [
        "# Import\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import xarray as xr\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "from matplotlib.colors import LogNorm\n",
        "import os\n",
        "from shapely.geometry import Point\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.linear_model import SGDOneClassSVM\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import f1_score\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download data sets"
      ],
      "metadata": {
        "id": "o2eBIRSWH6dg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading the Excel files\n",
        "grandvennes = pd.read_excel(\"https://raw.githubusercontent.com/CHGROSJEAN/2024_MLEES/main/Projet/Stations/GrandVennes.xlsx\")\n",
        "riandpre = pd.read_excel(\"https://raw.githubusercontent.com/CHGROSJEAN/2024_MLEES/main/Projet/Stations/RiandPre.xlsx\")\n",
        "chandieu = pd.read_excel(\"https://raw.githubusercontent.com/CHGROSJEAN/2024_MLEES/main/Projet/Stations/Chandieu.xlsx\")\n",
        "geopolis = pd.read_excel(\"https://raw.githubusercontent.com/CHGROSJEAN/2024_MLEES/main/Projet/Stations/Geopolis.xlsx\")\n",
        "lexplore = pd.read_excel(\"https://raw.githubusercontent.com/CHGROSJEAN/2024_MLEES/main/Projet/Stations/LExplore.xlsx\")\n",
        "bethusy = pd.read_excel(\"https://raw.githubusercontent.com/CHGROSJEAN/2024_MLEES/main/Projet/Stations/Bethusy.xlsx\")\n",
        "boisgentils = pd.read_excel(\"https://raw.githubusercontent.com/CHGROSJEAN/2024_MLEES/main/Projet/Stations/BoisGentils.xlsx\")\n",
        "elysee = pd.read_excel(\"https://raw.githubusercontent.com/CHGROSJEAN/2024_MLEES/main/Projet/Stations/Elysee.xlsx\")\n",
        "pontaise = pd.read_excel(\"https://raw.githubusercontent.com/CHGROSJEAN/2024_MLEES/main/Projet/Stations/Pontaise.xlsx\")\n",
        "rouvraie = pd.read_excel(\"https://raw.githubusercontent.com/CHGROSJEAN/2024_MLEES/main/Projet/Stations/Rouvraie.xlsx\")\n",
        "vclb = pd.read_excel(\"https://raw.githubusercontent.com/CHGROSJEAN/2024_MLEES/main/Projet/Stations/VersChezLesBlancs.xlsx\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oulEz3AxIbgs",
        "collapsed": true
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DateTime ajustment"
      ],
      "metadata": {
        "id": "HH3MQH5xGxYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensuring the 'DateTime' the column is of datetime type for both datasets\n",
        "grandvennes['DateTime'] = pd.to_datetime(grandvennes['DateTime'], dayfirst=True)\n",
        "riandpre['DateTime'] = pd.to_datetime(riandpre['DateTime'], dayfirst=True)\n",
        "chandieu['DateTime'] = pd.to_datetime(chandieu['DateTime'], dayfirst=True)\n",
        "geopolis['DateTime'] = pd.to_datetime(geopolis['DateTime'], dayfirst=True)\n",
        "lexplore['DateTime'] = pd.to_datetime(lexplore['DateTime'], dayfirst=True)\n",
        "bethusy['DateTime'] = pd.to_datetime(bethusy['DateTime'], dayfirst=True)\n",
        "boisgentils['DateTime'] = pd.to_datetime(boisgentils['DateTime'], dayfirst=True)\n",
        "elysee['DateTime'] = pd.to_datetime(elysee['DateTime'], dayfirst=True)\n",
        "pontaise['DateTime'] = pd.to_datetime(pontaise['DateTime'], dayfirst=True)\n",
        "rouvraie['DateTime'] = pd.to_datetime(rouvraie['DateTime'], dayfirst=True)\n",
        "vclb['DateTime'] = pd.to_datetime(vclb['DateTime'], dayfirst=True)\n",
        "\n",
        "\n",
        "\n",
        "# Setting the DateTime column as the index for easier time-based operations\n",
        "grandvennes.set_index('DateTime', inplace=True)\n",
        "riandpre.set_index('DateTime', inplace=True)\n",
        "chandieu.set_index('DateTime', inplace=True)\n",
        "geopolis.set_index('DateTime', inplace=True)\n",
        "lexplore.set_index('DateTime', inplace=True)\n",
        "bethusy.set_index('DateTime', inplace=True)\n",
        "boisgentils.set_index('DateTime', inplace=True)\n",
        "elysee.set_index('DateTime', inplace=True)\n",
        "pontaise.set_index('DateTime', inplace=True)\n",
        "rouvraie.set_index('DateTime', inplace=True)\n",
        "vclb.set_index('DateTime', inplace=True)"
      ],
      "metadata": {
        "id": "fyElIL3X6ghE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aligning all station to be merged in 1 dataset"
      ],
      "metadata": {
        "id": "d9bHQoKDG4yc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Round down the DateTime to the previous minute (removes seconds, truncating)\n",
        "grandvennes.index = grandvennes.index.floor('min')  # rounded to the nearest lower minute\n",
        "riandpre.index = riandpre.index.floor('min')\n",
        "bethusy.index = bethusy.index.floor('min')\n",
        "boisgentils.index = boisgentils.index.floor('min')\n",
        "chandieu.index = chandieu.index.floor('min')\n",
        "elysee.index = elysee.index.floor('min')\n",
        "lexplore.index = lexplore.index.floor('min')\n",
        "pontaise.index = pontaise.index.floor('min')\n",
        "rouvraie.index = rouvraie.index.floor('min')\n",
        "vclb.index = vclb.index.floor('min')\n",
        "geopolis.index = geopolis.index.floor('min')\n",
        "\n",
        "# Resample both datasets to ensure they have data every 3 minutes (if necessary)\n",
        "# Resampling to the closest 3-minute interval and filling missing values with NaN\n",
        "grandvennes_resampled = grandvennes.resample('3min').mean()\n",
        "riandpre_resampled = riandpre.resample('3min').mean()\n",
        "bethusy_resampled = bethusy.resample('3min').mean()\n",
        "boisgentils_resampled = boisgentils.resample('3min').mean()\n",
        "chandieu_resampled = chandieu.resample('3min').mean()\n",
        "elysee_resampled = elysee.resample('3min').mean()\n",
        "lexplore_resampled = lexplore.resample('3min').mean()\n",
        "pontaise_resampled = pontaise.resample('3min').mean()\n",
        "rouvraie_resampled = rouvraie.resample('3min').mean()\n",
        "vclb_resampled = vclb.resample('3min').mean()\n",
        "geopolis_resampled = geopolis.resample('3min').mean()\n",
        "\n",
        "\n",
        "# Align both datasets to the common time period (intersection of their timestamps)\n",
        "start_time = max(grandvennes_resampled.index.min(), riandpre_resampled.index.min(),bethusy_resampled.index.min(),\n",
        "                 boisgentils_resampled.index.min(),chandieu_resampled.index.min(),elysee_resampled.index.min(), lexplore_resampled.index.min(),\n",
        "                 pontaise_resampled.index.min(),rouvraie_resampled.index.min(),vclb_resampled.index.min(),geopolis_resampled.index.min())\n",
        "\n",
        "\n",
        "end_time = min(grandvennes_resampled.index.max(), riandpre_resampled.index.max(), bethusy_resampled.index.max(),\n",
        "               boisgentils_resampled.index.max(),chandieu_resampled.index.max(),elysee_resampled.index.max(),lexplore_resampled.index.max(),\n",
        "               pontaise_resampled.index.max(),rouvraie_resampled.index.max(),vclb_resampled.index.max(),geopolis_resampled.index.max())\n",
        "\n",
        "grandvennes_aligned = grandvennes_resampled.loc[start_time:end_time]\n",
        "riandpre_aligned = riandpre_resampled.loc[start_time:end_time]\n",
        "bethusy_aligned = bethusy_resampled.loc[start_time:end_time]\n",
        "boisgentils_aligned = boisgentils_resampled.loc[start_time:end_time]\n",
        "chandieu_aligned = chandieu_resampled.loc[start_time:end_time]\n",
        "elysee_aligned = elysee_resampled.loc[start_time:end_time]\n",
        "lexplore_aligned = lexplore_resampled.loc[start_time:end_time]\n",
        "pontaise_aligned = pontaise_resampled.loc[start_time:end_time]\n",
        "rouvraie_aligned = rouvraie_resampled.loc[start_time:end_time]\n",
        "vclb_aligned = vclb_resampled.loc[start_time:end_time]\n",
        "geopolis_aligned = geopolis_resampled.loc[start_time:end_time]\n",
        "\n",
        "# Drop rows with missing values from both datasets\n",
        "grandvennes_aligned = grandvennes_aligned.dropna()\n",
        "riandpre_aligned = riandpre_aligned.dropna()\n",
        "bethusy_aligned = bethusy_aligned.dropna()\n",
        "boisgentils_aligned = boisgentils_aligned.dropna()\n",
        "chandieu_aligned = chandieu_aligned.dropna()\n",
        "elysee_aligned = elysee_aligned.dropna()\n",
        "lexplore_aligned = lexplore_aligned.dropna()\n",
        "pontaise_aligned = pontaise_aligned.dropna()\n",
        "rouvraie_aligned = rouvraie_aligned.dropna()\n",
        "vclb_aligned = vclb_aligned.dropna()\n",
        "geopolis_aligned = geopolis_aligned.dropna()\n"
      ],
      "metadata": {
        "id": "uUiR4VAEGQbZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merging all stations datasets in 1 dataset"
      ],
      "metadata": {
        "id": "ZhE_mZ7XHCkt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge the datasets on the 'DateTime' index\n",
        "combined_data = pd.concat(\n",
        "    [\n",
        "        grandvennes_aligned[['Precipitation']].rename(columns={'Precipitation': 'Precipitation_Grandvennes'}),\n",
        "        riandpre_aligned[['Precipitation']].rename(columns={'Precipitation': 'Precipitation_Riandpre'}),\n",
        "        bethusy_aligned[['Precipitation']].rename(columns={'Precipitation': 'Precipitation_Bethusy'}),\n",
        "        boisgentils_aligned[['Precipitation']].rename(columns={'Precipitation': 'Precipitation_Boisgentils'}),\n",
        "        chandieu_aligned[['Precipitation']].rename(columns={'Precipitation': 'Precipitation_Chandieu'}),\n",
        "        elysee_aligned[['Precipitation']].rename(columns={'Precipitation': 'Precipitation_Elysee'}),\n",
        "        lexplore_aligned[['Precipitation']].rename(columns={'Precipitation': 'Precipitation_Lexplore'}),\n",
        "        pontaise_aligned[['Precipitation']].rename(columns={'Precipitation': 'Precipitation_Pontaise'}),\n",
        "        rouvraie_aligned[['Precipitation']].rename(columns={'Precipitation': 'Precipitation_Rouvraie'}),\n",
        "        vclb_aligned[['Precipitation']].rename(columns={'Precipitation': 'Precipitation_VCLB'}),\n",
        "        geopolis_aligned[['Precipitation']].rename(columns={'Precipitation': 'Precipitation_Geopolis'})\n",
        "    ],\n",
        "    axis=1,\n",
        "    join='inner'  # Ensures alignment on shared indices only\n",
        ")\n",
        "\n",
        "# Display the first few rows of the combined data\n",
        "print(\"Combined Precipitation Data:\")\n",
        "print(combined_data.head())\n",
        "print(combined_data.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDnxZYhbHCBx",
        "outputId": "7c11bed4-5fa7-4446-eb00-98362cfceaba"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined Precipitation Data:\n",
            "                     Precipitation_Grandvennes  Precipitation_Riandpre  \\\n",
            "DateTime                                                                 \n",
            "2023-01-19 14:03:00                        0.0                     5.0   \n",
            "2023-01-19 14:06:00                        0.0                     5.0   \n",
            "2023-01-19 14:09:00                        0.0                     2.0   \n",
            "2023-01-19 14:12:00                        0.0                     1.0   \n",
            "2023-01-19 14:15:00                        0.0                     0.0   \n",
            "\n",
            "                     Precipitation_Bethusy  Precipitation_Boisgentils  \\\n",
            "DateTime                                                                \n",
            "2023-01-19 14:03:00                    0.0                        0.0   \n",
            "2023-01-19 14:06:00                    0.0                        0.0   \n",
            "2023-01-19 14:09:00                    0.0                        0.0   \n",
            "2023-01-19 14:12:00                    0.0                        0.0   \n",
            "2023-01-19 14:15:00                    0.0                        0.0   \n",
            "\n",
            "                     Precipitation_Chandieu  Precipitation_Elysee  \\\n",
            "DateTime                                                            \n",
            "2023-01-19 14:03:00                     0.0                   0.0   \n",
            "2023-01-19 14:06:00                     0.0                   1.0   \n",
            "2023-01-19 14:09:00                     0.0                   0.0   \n",
            "2023-01-19 14:12:00                     0.0                   0.0   \n",
            "2023-01-19 14:15:00                     0.0                   0.0   \n",
            "\n",
            "                     Precipitation_Lexplore  Precipitation_Pontaise  \\\n",
            "DateTime                                                              \n",
            "2023-01-19 14:03:00                     0.0                    10.0   \n",
            "2023-01-19 14:06:00                     0.0                    10.0   \n",
            "2023-01-19 14:09:00                     0.0                    11.0   \n",
            "2023-01-19 14:12:00                     0.0                    11.0   \n",
            "2023-01-19 14:15:00                     0.0                    12.0   \n",
            "\n",
            "                     Precipitation_Rouvraie  Precipitation_VCLB  \\\n",
            "DateTime                                                          \n",
            "2023-01-19 14:03:00                     0.0                 0.0   \n",
            "2023-01-19 14:06:00                     0.0                 0.0   \n",
            "2023-01-19 14:09:00                     0.0                 0.0   \n",
            "2023-01-19 14:12:00                     0.0                 0.0   \n",
            "2023-01-19 14:15:00                     0.0                 0.0   \n",
            "\n",
            "                     Precipitation_Geopolis  \n",
            "DateTime                                     \n",
            "2023-01-19 14:03:00                     0.0  \n",
            "2023-01-19 14:06:00                     0.0  \n",
            "2023-01-19 14:09:00                     0.0  \n",
            "2023-01-19 14:12:00                     0.0  \n",
            "2023-01-19 14:15:00                     0.0  \n",
            "(57124, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = combined_data[['Precipitation_Grandvennes', 'Precipitation_Riandpre', 'Precipitation_Bethusy', 'Precipitation_Boisgentils', 'Precipitation_Chandieu', 'Precipitation_Elysee', 'Precipitation_Lexplore', 'Precipitation_Pontaise', 'Precipitation_Rouvraie', 'Precipitation_VCLB', 'Precipitation_Geopolis']]  # Features (precipitation from all stations)\n"
      ],
      "metadata": {
        "id": "9SDJO9oT3mf3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale the data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "PeeGUF7DcdeX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DBSCAN"
      ],
      "metadata": {
        "id": "oqcJk9WM3fSM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply DBSCAN\n",
        "dbscan = DBSCAN(eps=0.5, min_samples=5)  # Adjust `eps` and `min_samples` as needed\n",
        "labels = dbscan.fit_predict(X_scaled)\n",
        "\n",
        "# Pseudo-labels: Core points (+1), Noise points (-1)\n",
        "pseudo_labels = np.where(labels == -1, -1, 1)\n",
        "\n",
        "print(\"DBSCAN Labels:\", labels)\n",
        "print(\"Pseudo-Labels:\", pseudo_labels)\n",
        "\n",
        "# Use pseudo-labels to train SGDOneClassSVM\n",
        "from sklearn.svm import SGDOneClassSVM\n",
        "model = SGDOneClassSVM()\n",
        "model.fit(X_scaled)  # Model trains without labels\n",
        "\n",
        "# Evaluate the model using pseudo-labels\n",
        "from sklearn.metrics import f1_score\n",
        "predictions = model.predict(X_scaled)\n",
        "f1 = f1_score(pseudo_labels, predictions, pos_label=-1)\n",
        "print(\"F1 Score:\", f1)\n"
      ],
      "metadata": {
        "id": "t0Rzr09X3ga9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-Means"
      ],
      "metadata": {
        "id": "v0yKrxXf4PoK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply k-means\n",
        "kmeans = KMeans(n_clusters=3, random_state=42)  # Adjust `n_clusters` as needed\n",
        "labels = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "# Identify small clusters as anomalies\n",
        "cluster_sizes = np.bincount(labels)\n",
        "anomalous_clusters = np.where(cluster_sizes < 10)[0]  # Define a threshold for small clusters\n",
        "\n",
        "# Pseudo-labels: +1 for normal, -1 for anomalies\n",
        "pseudo_labels = np.array([1 if label not in anomalous_clusters else -1 for label in labels])\n",
        "\n",
        "print(\"k-means Labels:\", labels)\n",
        "print(\"Pseudo-Labels:\", pseudo_labels)\n",
        "\n",
        "# Use pseudo-labels to evaluate SGDOneClassSVM\n",
        "model = SGDOneClassSVM()\n",
        "model.fit(X_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "predictions = model.predict(X_scaled)\n",
        "f1 = f1_score(pseudo_labels, predictions, pos_label=-1)\n",
        "print(\"F1 Score:\", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJQwTnBv4PRy",
        "outputId": "b062407f-e199-4b9e-ed37-634a73cc01d6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k-means Labels: [0 0 0 ... 0 0 0]\n",
            "Pseudo-Labels: [1 1 1 ... 1 1 1]\n",
            "F1 Score: 0.0\n"
          ]
        }
      ]
    }
  ]
}